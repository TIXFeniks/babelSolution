{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64\n",
      "env: LIBRARY_PATH=/usr/local/cuda-8.0/lib64\n",
      "env: PATH=/usr/local/cuda-8.0/include:/usr/local/cuda-8.0/bin:/home/apanin/anaconda/bin:/opt/WinCC_OA/3.11/bin:/opt/pvss/pvss2_v3.8/bin:/home/apanin/anaconda/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/opt/fmc/bin:/group/online/bin:/group/online/scripts:/home/apanin/bin:/home/apanin/bin\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: MKL_THREADING_LAYER=GNU\n",
      "env: THEANO_FLAGS=device=cuda0,gpuarray.preallocate=0.99\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "%env LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64\n",
    "%env LIBRARY_PATH=/usr/local/cuda-8.0/lib64\n",
    "%env PATH=/usr/local/cuda-8.0/include:/usr/local/cuda-8.0/bin:/home/apanin/anaconda/bin:/opt/WinCC_OA/3.11/bin:/opt/pvss/pvss2_v3.8/bin:/home/apanin/anaconda/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/opt/fmc/bin:/group/online/bin:/group/online/scripts:/home/apanin/bin:/home/apanin/bin\n",
    "sys.path.insert(0,\"/home/apanin/rit_my/\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env MKL_THREADING_LAYER=GNU\n",
    "%env THEANO_FLAGS=device=cuda0,gpuarray.preallocate=0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 6021 on context None\n",
      "Preallocating 11596/12207 Mb (0.950000) on cuda0\n",
      "Mapped name None to device cuda0: GeForce GTX TITAN X (0000:02:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 1\n"
     ]
    }
   ],
   "source": [
    "!./preprocess.sh data/indomain_training/indomain.de-en.de preprocessed/ en de\n",
    "!./preprocess.sh data/indomain_training/indomain.de-en.en preprocessed/ de en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRC_PATH = \"data/wmt/train.tok.bpe.32000.en\" \n",
    "DST_PATH = \"data/wmt/train.tok.bpe.32000.de\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_src = []\n",
    "with open(SRC_PATH, 'r') as f:\n",
    "    raw_src = f.readlines()\n",
    "raw_dst = []\n",
    "with open(DST_PATH, 'r') as f:\n",
    "    raw_dst = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_ends(sents):\n",
    "    for i in range(len(sents)):\n",
    "        sents[i] = sents[i][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix_ends(raw_src)\n",
    "fix_ends(raw_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, sentences):\n",
    "        tokens = set()\n",
    "        for s in sentences:\n",
    "            tokens.update(s.split(' '))\n",
    "        self.tokens = [ \"__BOS__\",\"__EOS__\", \"__PAD__\"] + list(tokens)\n",
    "        self.EOS = 1\n",
    "        self.BOS = 0 # BOS should be zero to let the model generate starting with zero as an input\n",
    "        self.PAD = 2\n",
    "        self.len = len(self.tokens)\n",
    "        self.token2id = {token: i for i, token in enumerate(self.tokens)}\n",
    "    def tokenize(self, sentence):\n",
    "        if not sentence.endswith(\"__EOS__\"):\n",
    "            sentence += \" __EOS__\"\n",
    "        if not sentence.startswith(\"__BOS__\"):\n",
    "            sentence = \"__BOS__ \" + sentence\n",
    "        return [self.token2id[token] for token in sentence.split(' ')]\n",
    "    def detokenize(self, sentence):\n",
    "        return \" \".join([self.tokens[token] for token in sentence])\n",
    "    def tokenize_many(self, sentences):\n",
    "        return [self.tokenize(sent) for sent in sentences]\n",
    "    def detokenize_many(self, sentences):\n",
    "        return [self.detokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"vocabs.pkl\", 'rb') as f:\n",
    "    dst_voc = pkl.load(f)\n",
    "    src_voc = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_voc = Vocab(raw_src)\n",
    "dst_voc = Vocab(raw_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = src_voc.tokenize_many(raw_src)\n",
    "Y = dst_voc.tokenize_many(raw_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_text = train_test_split(X,Y, test_size = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from batch_iterator import iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=theano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=theano\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD+CAYAAAA09s7qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0927271198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(lambda x: len(x), X)), bins = 100,log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequencea','int32')\n",
    "input_mask = T.neq(input_sequence, src_voc.PAD)\n",
    "\n",
    "target_values = T.matrix('actual next token','int32')\n",
    "target_mask = T.neq(target_values, dst_voc.PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=input_mask)\n",
    "\n",
    "#encoder\n",
    "l_emb = L.EmbeddingLayer(l_in, src_voc.len, 128)\n",
    "\n",
    "l_rnn = L.LSTMLayer(l_emb, 256, nonlinearity=T.tanh, mask_input= l_mask)\n",
    "l_rnn = L.concat([l_emb,l_rnn], axis=-1)\n",
    "l_encoded = l_rnn = L.LSTMLayer(l_rnn, CODE_SIZE, nonlinearity=T.tanh, mask_input= l_mask)\n",
    "\n",
    "l_trans = L.InputLayer((None, None), input_var= target_values[:,:-1])\n",
    "l_trans_mask = L.InputLayer((None, None), input_var= target_mask[:,:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent.recurrence import Recurrence\n",
    "from agentnet.memory import AttentionLayer,LSTMCell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import ProbabilisticResolver, GreedyResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoLSTMCell:\n",
    "    def __init__(self, input_or_inputs, num_units = None, *args, name=None, **kwargs):\n",
    "        self.p_cell = L.InputLayer((None, num_units), \n",
    "                       name=\"previous cell state\" if name == None else name + \" previous cell state\")\n",
    "        self.p_out = L.InputLayer((None, num_units), \n",
    "                       name=\"previous out state\" if name == None else name + \" previous out state\")\n",
    "        self.cell, self.out = LSTMCell(self.p_cell, self.p_out, input_or_inputs, num_units, *args,name=name, **kwargs)\n",
    "    def get_automatic_updates(self):\n",
    "        return {self.cell: self.p_cell, self.out: self.p_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TemperatureResolver(ProbabilisticResolver):\n",
    "    def __init__(self, incoming, tau, **kwargs):\n",
    "        self.tau = tau\n",
    "        super(TemperatureResolver, self).__init__(incoming,**kwargs)\n",
    "    def get_output_for(self, policy, **kwargs):\n",
    "        policy = policy ** (1/self.tau)\n",
    "        policy /= policy.sum()\n",
    "        return super(TemperatureResolver, self).get_output_for(policy, **kwargs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class decoder_step:\n",
    "    #inputs\n",
    "    encoder = L.InputLayer((None, None ,CODE_SIZE), name='encoded sequence')\n",
    "    encoder_mask = L.InputLayer((None, None), name='encoded sequence')\n",
    "    \n",
    "    inp = L.InputLayer((None,),name='current character')\n",
    "    \n",
    "    l_target_emb = L.EmbeddingLayer(inp, dst_voc.len, 128)\n",
    "    \n",
    "    #recurrent part\n",
    "    \n",
    "    l_rnn1 = AutoLSTMCell(l_target_emb, 128, name=\"lstm1\")\n",
    "    \n",
    "    query = L.DenseLayer(l_rnn1.out, 128, nonlinearity=None)\n",
    "    attn = AttentionLayer(encoder, query, 128, mask_input= encoder_mask)['attn']\n",
    "    \n",
    "    l_rnn = L.concat([attn, l_rnn1.out, l_target_emb])\n",
    "    \n",
    "    l_rnn2 = AutoLSTMCell(l_rnn, 128, name=\"lstm1\")\n",
    "    \n",
    "    next_token_probas = L.DenseLayer(l_rnn2.out, dst_voc.len, nonlinearity=T.nnet.softmax)\n",
    "    \n",
    "    #pick next token from predicted probas\n",
    "    next_token = ProbabilisticResolver(next_token_probas)\n",
    "    \n",
    "    tau = T.scalar(\"sample temperature\", \"float32\")\n",
    "    \n",
    "    next_token_temperatured = TemperatureResolver(next_token_probas, tau)\n",
    "    next_token_greedy = GreedyResolver(next_token_probas)\n",
    "    \n",
    "    auto_updates = {**l_rnn1.get_automatic_updates(),\n",
    "                    **l_rnn2.get_automatic_updates()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37943"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_voc.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "training_loop = Recurrence(\n",
    "    state_variables=OrderedDict(decoder_step.auto_updates),\n",
    "    input_sequences=OrderedDict({decoder_step.inp:l_trans}), \n",
    "    tracked_outputs=[decoder_step.next_token_probas,],\n",
    "    input_nonsequences= OrderedDict({decoder_step.encoder: l_encoded, decoder_step.encoder_mask: l_mask} ),\n",
    "    mask_input=l_trans_mask,\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W, lstm1.b_to_ingate, lstm1.W_lstm1 previous out state_to_ingate, lstm1.W_ctrl1_to_ingate, lstm1.b_to_forgetgate, lstm1.W_lstm1 previous out state_to_forgetgate, lstm1.W_ctrl1_to_forgetgate, lstm1.b_to_cell, lstm1.W_lstm1 previous out state_to_cell, lstm1.W_ctrl1_to_cell, lstm1.b_to_outgate, lstm1.W_lstm1 previous out state_to_outgate, lstm1.W_ctrl1_to_outgate, lstm1.W_cell_to_ingate_peephole.scales, lstm1.W_cell_to_forgetgate_peephole.scales, lstm1.W_cell_to_outgate_peephole.scales, W, b, enc_to_hid, dec_to_hid, hid_to_logit, lstm1.b_to_ingate, lstm1.W_lstm1 previous out state_to_ingate, lstm1.W_ctrl1_to_ingate, lstm1.b_to_forgetgate, lstm1.W_lstm1 previous out state_to_forgetgate, lstm1.W_ctrl1_to_forgetgate, lstm1.b_to_cell, lstm1.W_lstm1 previous out state_to_cell, lstm1.W_ctrl1_to_cell, lstm1.b_to_outgate, lstm1.W_lstm1 previous out state_to_outgate, lstm1.W_ctrl1_to_outgate, lstm1.W_cell_to_ingate_peephole.scales, lstm1.W_cell_to_forgetgate_peephole.scales, lstm1.W_cell_to_outgate_peephole.scales, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(training_loop,trainable=True)\n",
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_probas_flat = L.get_output(training_loop[decoder_step.next_token_probas]).reshape((-1,dst_voc.len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(train_probas_flat, target_values[:,1:].reshape((-1,)))\n",
    "loss = loss.reshape((-1,target_mask.shape[1]-1))\n",
    "loss = (loss * target_mask[:,1:]).sum(axis= 1).mean()\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(train_probas_flat, target_values[:,1:].reshape((-1,)))\n",
    "loss = (loss * target_mask[:,1:].ravel()).sum() / target_mask.sum()\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: local_reshape_dimshuffle\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673226068320 Reshape{2}.0\n",
      "  Op Reshape{2}(CGemv{no_inplace}.0, HostFromGpu(gpuarray).0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_reshape_dimshuffle. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |Elemwise{tanh,no_inplace} [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |Reshape{2} [id J] <TensorType(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  Reshape{2} [id S] <TensorType(float32, matrix)> ''   \n",
      "   |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_reshape_dimshuffle\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673225884560 Reshape{2}.0\n",
      "  Op Reshape{2}(CGemv{no_inplace}.0, HostFromGpu(gpuarray).0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_reshape_dimshuffle. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |Elemwise{tanh,no_inplace} [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |Reshape{2} [id J] <TensorType(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  Reshape{2} [id S] <TensorType(float32, matrix)> ''   \n",
      "   |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): SeqOptimizer apply <theano.gpuarray.opt.GraphToGPU object at 0x7f083520a6d8>\n",
      "ERROR (theano.gof.opt): Traceback:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 251, in apply\n",
      "    sub_prof = optimizer.optimize(fgraph)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 97, in optimize\n",
      "    ret = self.apply(fgraph, *args, **kwargs)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gpuarray/opt.py\", line 430, in apply\n",
      "    newnode = node.clone_with_new_inputs([mapping.get(i) for i in node.inputs])\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/graph.py\", line 242, in clone_with_new_inputs\n",
      "    new_inputs[i] = curr.type.filter_variable(new)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/tensor/type.py\", line 234, in filter_variable\n",
      "    self=self))\n",
      "TypeError: Cannot convert Type TensorType(float32, matrix) (of Variable HostFromGpu(gpuarray).0) into Type TensorType(float32, col). You can try to manually convert HostFromGpu(gpuarray).0 into a TensorType(float32, col).\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673225193008 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |Elemwise{tanh,no_inplace} [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |Reshape{2} [id J] <TensorType(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id S] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id T] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id U] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223702512 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |Elemwise{tanh,no_inplace} [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |Reshape{2} [id J] <TensorType(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id S] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id T] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id U] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223361872 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |Elemwise{tanh,no_inplace} [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |HostFromGpu(gpuarray) [id J] <TensorType(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id S] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id T] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id U] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223409224 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |InplaceDimShuffle{1,0} [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |HostFromGpu(gpuarray) [id I] <TensorType(float32, matrix)> ''   \n",
      "   |   |   |GpuElemwise{tanh,no_inplace} [id J] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id S] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id T] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id U] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223422752 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |CGemv{no_inplace} [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |AllocEmpty{dtype='float32'} [id D] <TensorType(float32, vector)> ''   \n",
      "   |   | |Shape_i{2} [id E] <TensorType(int64, scalar)> ''   \n",
      "   |   |   |<GpuArrayType<None>(float32, 3D)> [id F] <GpuArrayType<None>(float32, 3D)>\n",
      "   |   |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |   |HostFromGpu(gpuarray) [id H] <TensorType(float32, matrix)> ''   \n",
      "   |   | |InplaceGpuDimShuffle{1,0} [id I] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |   |   |GpuElemwise{tanh,no_inplace} [id J] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |   |Reshape{1} [id K] <TensorType(float32, vector)> ''   \n",
      "   |   | |Rebroadcast{?,?,0} [id L] <TensorType(float32, 3D)> ''   \n",
      "   |   | | |IncSubtensor{Inc;::, ::, int64} [id M] <TensorType(float32, (False, False, True))> ''   \n",
      "   |   | |MakeVector{dtype='int64'} [id N] <TensorType(int64, vector)> ''   \n",
      "   |   |   |Elemwise{switch,no_inplace} [id O] <TensorType(int64, scalar)> ''   \n",
      "   |   |TensorConstant{0.0} [id P] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id R] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id S] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id T] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id U] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id Q] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223408272 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "   | |HostFromGpu(gpuarray) [id C] <TensorType(float32, vector)> ''   \n",
      "   |   |GpuGemv{inplace=False} [id D] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     |GpuFromHost<None> [id E] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id F] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |     |InplaceGpuDimShuffle{1,0} [id H] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     | |GpuElemwise{tanh,no_inplace} [id I] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     |GpuFromHost<None> [id J] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id K] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{0.0} [id L] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id N] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id O] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id P] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |GpuFromHost<None> [id Q] <GpuArrayType<None>(float32, col)> ''   \n",
      "     | |InplaceDimShuffle{0,x} [id B] <TensorType(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(HostFromGpu(gpuarray).0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223532952 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |HostFromGpu(gpuarray) [id B] <TensorType(float32, col)> ''   \n",
      "   | |InplaceGpuDimShuffle{0,x} [id C] <GpuArrayType<None>(float32, col)> ''   \n",
      "   |   |GpuGemv{inplace=False} [id D] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     |GpuFromHost<None> [id E] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id F] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |     |InplaceGpuDimShuffle{1,0} [id H] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     | |GpuElemwise{tanh,no_inplace} [id I] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     |GpuFromHost<None> [id J] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id K] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{0.0} [id L] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id N] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id O] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id P] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |InplaceGpuDimShuffle{0,x} [id C] <GpuArrayType<None>(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_gpua_reshape\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(HostFromGpu(gpuarray).0, HostFromGpu(gpuarray).0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/opt.py\", line 2074, in process_node\n",
      "    remove=remove)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 569, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/toolbox.py\", line 518, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/home/apanin/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/fg.py\", line 486, in replace\n",
      "    \". The type of the replacement must be the same.\", old, new)\n",
      "theano.gof.toolbox.BadOptimization: BadOptimization Error \n",
      "  Variable: id 139673223798456 HostFromGpu(gpuarray).0\n",
      "  Op HostFromGpu(gpuarray)(GpuReshape{2}.0)\n",
      "  Value Type: <class 'NoneType'>\n",
      "  Old Value:  None\n",
      "  New Value:  None\n",
      "  Reason:  local_gpua_reshape. The type of the replacement must be the same.\n",
      "  Old Graph:\n",
      "  Reshape{2} [id A] <TensorType(float32, col)> ''   \n",
      "   |HostFromGpu(gpuarray) [id B] <TensorType(float32, col)> ''   \n",
      "   | |InplaceGpuDimShuffle{0,x} [id C] <GpuArrayType<None>(float32, col)> ''   \n",
      "   |   |GpuGemv{inplace=False} [id D] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     |GpuFromHost<None> [id E] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id F] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{1.0} [id G] <TensorType(float32, scalar)>\n",
      "   |     |InplaceGpuDimShuffle{1,0} [id H] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     | |GpuElemwise{tanh,no_inplace} [id I] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "   |     |GpuFromHost<None> [id J] <GpuArrayType<None>(float32, vector)> ''   \n",
      "   |     | |HostFromGpu(gpuarray) [id K] <TensorType(float32, vector)> ''   \n",
      "   |     |TensorConstant{0.0} [id L] <TensorType(float32, scalar)>\n",
      "   |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "     |<GpuArrayType<None>(int64, vector)> [id N] <GpuArrayType<None>(int64, vector)>\n",
      "\n",
      "  New Graph:\n",
      "  HostFromGpu(gpuarray) [id O] <TensorType(float32, matrix)> ''   \n",
      "   |GpuReshape{2} [id P] <GpuArrayType<None>(float32, matrix)> ''   \n",
      "     |InplaceGpuDimShuffle{0,x} [id C] <GpuArrayType<None>(float32, col)> ''   \n",
      "     |HostFromGpu(gpuarray) [id M] <TensorType(int64, vector)> ''   \n",
      "\n",
      "\n",
      "Hint: relax the tolerance by setting tensor.cmp_sloppy=1\n",
      "  or even tensor.cmp_sloppy=2 for less-strict comparison\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, target_values], loss\n",
    "                        , updates=updates+training_loop.get_automatic_updates(), allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = T.scalar(dtype='int32')\n",
    "feedback_loop = Recurrence(\n",
    "    state_variables=OrderedDict({**decoder_step.auto_updates,\n",
    "                     decoder_step.next_token:decoder_step.inp}),\n",
    "    tracked_outputs=[decoder_step.next_token_probas, decoder_step.next_token],\n",
    "    input_nonsequences= OrderedDict({decoder_step.encoder: l_encoded, decoder_step.encoder_mask: l_mask} ),\n",
    "    batch_size=input_sequence.shape[0],\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_tokens = L.get_output(feedback_loop[decoder_step.next_token])\n",
    "\n",
    "generate_sample = theano.function([input_sequence ,n_steps],generated_tokens,\n",
    "                                  updates=feedback_loop.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedback_loop_greedy = Recurrence(\n",
    "    state_variables=OrderedDict({**decoder_step.auto_updates,\n",
    "                     decoder_step.next_token_greedy:decoder_step.inp}),\n",
    "    tracked_outputs=[decoder_step.next_token_probas, decoder_step.next_token_greedy],\n",
    "    input_nonsequences= OrderedDict({decoder_step.encoder: l_encoded, decoder_step.encoder_mask: l_mask} ),\n",
    "    batch_size=input_sequence.shape[0],\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_tokens_greedy = L.get_output(feedback_loop_greedy[decoder_step.next_token_greedy])\n",
    "\n",
    "generate_sample_greedy = theano.function([input_sequence ,n_steps],generated_tokens_greedy,\n",
    "                                  updates=feedback_loop_greedy.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedback_loop_temp = Recurrence(\n",
    "    state_variables=OrderedDict({**decoder_step.auto_updates,\n",
    "                     decoder_step.next_token_temperatured:decoder_step.inp}),\n",
    "    tracked_outputs=[decoder_step.next_token_probas, decoder_step.next_token_temperatured],\n",
    "    input_nonsequences= OrderedDict({decoder_step.encoder: l_encoded, decoder_step.encoder_mask: l_mask} ),\n",
    "    batch_size=input_sequence.shape[0],\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_tokens_temp = L.get_output(feedback_loop_temp[decoder_step.next_token_temperatured])\n",
    "\n",
    "generate_sample_temp = theano.function([input_sequence ,n_steps, decoder_step.tau],generated_tokens_temp,\n",
    "                                  updates=feedback_loop_temp.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(src, N=MAX_LEN,t=1,n_snippets=1, greedy=False):\n",
    "    src = [src_voc.tokenize(src)]\n",
    "    \n",
    "    snippets = []\n",
    "    for _ in range(n_snippets):\n",
    "        sample_ix = generate_sample_greedy(src, N)[0] if greedy else generate_sample_temp(src, N, t)[0]\n",
    "        random_snippet = dst_voc.detokenize(sample_ix)\n",
    "        if random_snippet.find(\"__EOS__\") > 0:\n",
    "            random_snippet = random_snippet[:random_snippet.find(\"__EOS__\")+1]\n",
    "        snippets.append(random_snippet)\n",
    "        \n",
    "    print(\"----\\n %s \\n----\" % '; '.join(snippets).replace(\"@@ \", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I should now like to comment on the issue itself \n",
      "----\n",
      " Ich mchte auch auf der Frage der Frage  _ \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(raw_src[100])\n",
    "translate(raw_src[100], t = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_dict = {str(i): weight for i, weight in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load(\"weights.npz\") as f:\n",
    "    for key in weights_dict:\n",
    "        weights_dict[key].set_value(f[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4.43726015091:   0%|          | 1/86679.92 [00:19<457:29:52, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent:\n",
      "It does this with suppliers web@@ mails in co@@ .@@ uk or com@@ .@@ fr \n",
      "Real translation\n",
      "Dies funktioniert es mit den Web@@ mail Anbieter in com@@ .@@ fr co@@ .@@ uk oder \n",
      "translated\n",
      "----\n",
      " Sie haben ein und der Web-.-...info  _; Dieser von Ihrer persnlichen Daten in der Suche nach der Online-Website - und fr Sie  _ \n",
      "----\n",
      "Epoch 0 average loss = 4.422812223434448\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0fLAevgJ4MwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f084f3f5e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4.52462807655:   0%|          | 320/86679.92 [10:23<46:43:23,  1.95s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "view_window = 500\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    tq = tqdm(iterate_minibatches(X_train,Y_train, batchsize=batch_size, shuffle= True),\n",
    "              total= len(X_train) / batch_size)\n",
    "    for x, y in tq:\n",
    "        padded_x = pad_sequences(x, value= src_voc.PAD, maxlen=MAX_LEN, padding=\"post\")\n",
    "        padded_y = pad_sequences(y, value= dst_voc.PAD, maxlen=MAX_LEN, padding=\"post\")\n",
    "        try:\n",
    "            cost += [train(padded_x[:,:MAX_LEN], padded_y[:,:MAX_LEN])]#!!! fix\n",
    "            if len(cost) % 10 == 1:\n",
    "                tq.set_description(str(np.mean(cost[-50:])))\n",
    "            if len(cost) % view_window == 2:\n",
    "                translating_ind = np.random.randint(len(raw_src))\n",
    "\n",
    "                print(\"Sent:\")\n",
    "                print(raw_src[translating_ind])\n",
    "                print(\"Real translation\")\n",
    "                print(raw_dst[translating_ind])\n",
    "                print(\"translated\")\n",
    "                translate(raw_src[translating_ind],n_snippets=2, t=0.5)\n",
    "\n",
    "                print(\"Epoch {} average loss = {}\".format(epoch, np.mean(cost[-view_window:])))\n",
    "                plt.plot(cost[-view_window:])\n",
    "                plt.show()\n",
    "        except KeyboardInterrupt:\n",
    "            tq.close()\n",
    "            raise KeyboardInterrupt\n",
    "        except Exception as e:\n",
    "            sleep(1)\n",
    "            print(e)\n",
    "            print(max(list(map(len, x))))\n",
    "            print(max(list(map(len, y))))\n",
    "            #raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_dict = {str(i): weight for i, weight in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savez(\"weights.npz\", **{key: weights_dict[key].get_value() for key in weights_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.load(\"weights.npz\") as f:\n",
    "    for key in weights_dict:\n",
    "        weights_dict[key].set_value(f[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = Vocab(raw_dst)\n",
    "v1 = Vocab(raw_src)\n",
    "\n",
    "v.tokens = dst_voc.tokens\n",
    "v1.tokens = src_voc.tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import pickle as pkl\n",
    "with open(\"vocabs.pkl\", 'wb') as f:\n",
    "    pkl.dump(v,f)\n",
    "    pkl.dump(v1,f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBK6iEiCUEIXEUkQSugiIgni/wPaggZ6DQ6VHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4347fb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost[:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translating_ind = np.random.randint(len(raw_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This clas@@ h is not inevitable , and we don &apos;t want it \n",
      "Bitte sehen Sie sich unser neues Video an und unterzeichnen Sie die folgende Peti@@ tion . Wenn sich die politischen Fhrer Ende Mrz treffen , wird ihnen unsere Botschaft auf eine Art und Weise zu@@ gestellt werden , die sie nicht ignorieren knnen ..\n",
      "----\n",
      " Das ist nicht nur , und wir sind nicht nur nicht zu tun  _ \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(raw_src[translating_ind])\n",
    "print(raw_dst[translating_ind])\n",
    "translate(raw_src[translating_ind],n_snippets=1, t=0.1, greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1, 26074,   190,     0,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "           2,     2,     2,     2,     2,     2,     2,     2,     2,     2], dtype=int32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
