{
        "hid_size": 512,
        "ff_size": 2048,
        "num_heads": 4,
        "num_layers": 4,
        "rescale_emb": true,
        "relu_dropout": 0.1,
        "res_dropout": 0.1,
        "attn_dropout": 0.1,
        "inp_emb_bias": true,
        "res_steps": "nlda",
        "normalize_out": true,
        "force_bos": true,
        "batch_size": 32
}
