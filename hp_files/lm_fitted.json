{
        "hid_size": 256,
        "ff_size": 1024,
        "num_heads": 4,
        "num_layers": 4,
        "rescale_emb": true,
        "relu_dropout": 0.0,
        "res_dropout": 0.0,
        "attn_dropout": 0.0,
        "inp_emb_bias": true,
        "out_emb_bias": true,
        "res_steps": "nlda",
        "normalize_out": true,
        "force_bos": true,
        "batch_size": 32
}
