{
    "hid_size": 32,
    "ff_size": 128,
    "num_heads": 4,
    "num_layers": 4,
    "rescale_emb": true,
    "relu_dropout": 0.0,
    "res_dropout": 0.0,
    "attn_dropout": 0.0,
    "inp_emb_bias": true,
    "res_steps": "nlda",
    "normalize_out": true,
    "force_bos": true,
    "batch_size": 32
}