{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 1\n"
     ]
    }
   ],
   "source": [
    "!./preprocess.sh data/indomain_training/indomain.de-en.de preprocessed/ en de\n",
    "!./preprocess.sh data/indomain_training/indomain.de-en.en preprocessed/ de en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRC_PATH = \"preprocessed/indomain.de-en.de.bpe\" \n",
    "DST_PATH = \"preprocessed/indomain.de-en.en.bpe\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_src = []\n",
    "with open(SRC_PATH, 'r') as f:\n",
    "    raw_src = f.readlines()\n",
    "raw_dst = []\n",
    "with open(DST_PATH, 'r') as f:\n",
    "    raw_dst = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_ends(sents):\n",
    "    for i in range(len(sents)):\n",
    "        sents[i] = sents[i][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix_ends(raw_src)\n",
    "fix_ends(raw_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, sentences):\n",
    "        tokens = set()\n",
    "        for s in sentences:\n",
    "            tokens.update(s.split(' '))\n",
    "        self.tokens = [\"__EOS__\", \"__BOS__\", \"__PAD__\"] + list(tokens)\n",
    "        self.EOS = 0\n",
    "        self.BOS = 1\n",
    "        self.PAD = 2\n",
    "        self.len = len(tokens)\n",
    "        self.token2id = {token: i for i, token in enumerate(self.tokens)}\n",
    "    def tokenize(self, sentence):\n",
    "        if not sentence.endswith(\"__EOS__\"):\n",
    "            sentence += \" __EOS__\"\n",
    "        if not sentence.startswith(\"__BOS__\"):\n",
    "            sentence = \"__BOS__ \" + sentence\n",
    "        return [self.token2id[token] for token in sentence.split(' ')]\n",
    "    def detokenize(self, sentence):\n",
    "        return \" \".join([self.tokens[token] for token in sentence])\n",
    "    def tokenize_many(self, sentences):\n",
    "        return [self.tokenize(sent) for sent in sentences]\n",
    "    def detokenize_many(self, sentences):\n",
    "        return [self.dekenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_voc = Vocab(raw_src)\n",
    "dst_voc = Vocab(raw_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = zip(src_voc.tokenize_many(raw_src), dst_voc.tokenize_many(raw_dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__BOS__ returns the value of the number P@@ i  __EOS__',\n",
       " '__BOS__ liefert den Wert der Zahl P@@ i  __EOS__')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_voc.detokenize(data[11][0]),dst_voc.detokenize(data[11][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [x for x,y in data]\n",
    "Y = [y for x,y in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_text = train_test_split(X,Y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from batch_iterator import iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=theano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=theano\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAECCAYAAAASDQdFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFQFJREFUeJzt3X2wHXdZwPHvc5O+pMBtoWKCDUkQpmamA1KGSUFEzlgw\ngQ5E3qYN0wE60wHRaRkYNYwycxP9B8exihRx1BAVjQGU2lYoFIdeasVKsZTwkjSRl7yRXHlpIQIT\nCX38Y/fmntzcJHvv2XP2nLvfz0wmu79z7+6Ts5tnf+e3z/ltZCaSpHYYazoASdLgmPQlqUVM+pLU\nIiZ9SWoRk74ktYhJX5JaxKQvSS1i0pekFlnaj41GRAC/D4wDD2TmB/qxH0nS/PSrp78RWAn8H3Co\nT/uQJM1TpaQfEdsiYioids1q3xAReyJib0Rs7nrp54B/z8zfBH69xnglST2o2tPfDqzvboiIMeDW\nsv0KYFNErC1fPgQ8Ui6fqCFOSVINKiX9zLyPmSQ+bR2wLzP3Z+aPgZ0UwzoAHwE2RMS7gXvrClaS\n1JtebuReBhzsWj9EcSEgM38E3Hi2X44Ip/eUpAXIzFjo7zZasjkxMcE999xDZg7Nn4mJicZjMCZj\namNcxnT2P/fccw8TExM9591eevqHgVVd6yvLtsq2bNnSw+4lqT06nQ6dToetW7f2tJ359PSj/DPt\nAeAZEbE6Is4HrgPumM/Ot2zZwuTk5Hx+RZJaaXJyspaOctWSzR3AZ4DLI+JARNyQmT8BbgLuBr4M\n7MzM3fPZ+ZYtW+h0OvMMub+GLR4wpqqMqbphjMuYzq7T6dSS9COzmfupEZETExMnP7JIks5scnKS\nyclJtm7dSvZwI7fRpN/UviVpVEVET0nfCdckqUUaTfreyJWkauq6kevwjiSNEId3JEmVObwjSSPA\n4R1JaiGHdyRJlTm8I0kjwOEdSWohh3ckSZWZ9CWpRUz6ktQi3siVpBHgjVxJaiFv5EqSKjPpS1KL\nmPQlqUVM+pLUIiZ9SWoRSzYlaQRYsilJLWTJpiSpMpO+JLWISV+SWsSkL0kt0pekHxEvioh7I+J9\nEfFL/diHJGn++tXTT+AYcAFwqE/7kCTNU6WkHxHbImIqInbNat8QEXsiYm9EbJ5uz8x7M/Ma4B3A\n751pu1df/auMjy9nfHw5T3nK0zly5MhC/x2SpAqq9vS3A+u7GyJiDLi1bL8C2BQRa2f93qPA+Wfa\n6IMPfo5jxz7OsWO7+MEPlnH06NHqkUuS5m1plR/KzPsiYvWs5nXAvszcDxARO4GNwJ6IeCXFxeBi\nigvDWTwZWE7EefOLXJI0b5WS/hlcBhzsWj9EcSEgM28DbjvXBn70o+8DtwDjnDhxrIdQJGlxmpyc\nrHW6ml6Sfs+WLRvn+PG3AytZuvT2JkORpKHU6XTodDon17du3drT9npJ+oeBVV3rK8u2yoqe/n8A\nr+0hDEla/Orq8c+nZDPKP9MeAJ4REasj4nzgOuCOniOSJPVN1ZLNHcBngMsj4kBE3JCZPwFuAu4G\nvgzszMzd89n5smXjwPPnGbIktU+n06llauWq1TuvO0P7XcBdPUchSRqIRm/kOqYvSdXUNabf6ENU\nLrnkMh599H5gJePjVzI5+X6uvPLKRuKRpFHQ60NU7OlL0giwpy9JLeTjEiVJlTm8I0kjwOEdSWoh\nh3ckSZWZ9CWpRRzTl6QR4Ji+JLWQY/qSpMpM+pLUIo7pS9IIcExfklrIMX1JUmUmfUlqEZO+JLWI\nSV+SWsSkL0ktYsmmJI0ASzYlqYUs2ZQkVWbSl6QWGaqk/5KXvJyIICJYsWJN0+FI0qLT6I3c2b7z\nncNAcY9hamrBQ1aSpDPoW08/Ii6KiAci4mX92ockaX76ObyzGfhgH7cvSZqnSkk/IrZFxFRE7JrV\nviEi9kTE3ojY3NX+YuArwLcAx2kkaUhU7elvB9Z3N0TEGHBr2X4FsCki1pYvd4CrgNcBN9YSqSSp\nZ5Vu5GbmfRGxelbzOmBfZu4HiIidwEZgT2a+s2x7PfDtGuOVJPWgl+qdy4CDXeuHKC4EJ2Xm355t\nA8U0DLcA45w4cayHUCRpcapr+oVpladhKHv6d2bms8r1VwPrM/NN5fr1wLrMvLni9k6bhuH733+I\n6ZJNCJqaIkKShlWv0zD00tM/DKzqWl9ZtlXmhGuSVM3AJ1yLiDUUPf1nlutLgIeBq4EjwGeBTZm5\nu+L27OlL0jwNpKcfETsoKnIujYgDwERmbo+Im4C7KaqAtlVN+NPs6UtSNYtyamV7+pJ0dk2O6ffM\nnr4kVWNPX5JayJ6+JLWAPX1JaqFF/LjEC3ygiiTVbIiHd47jA1UkqdCK4R2HeiTpVIt4eEeSVDeT\nviS1SKNJf2ZMf2FWrFjjzV5JrTA5OcmWLVt63s6IjOlfSHFjF5YvX83Ro9+Y3gaO+0tqk5H+clZ1\n3ZU8F5bJXpI0XyM4pj99AbBXL0nzNcR1+pKkaa2r06+y7Ji+pMXOOn1JUmWLKOk7V48kncuIVO9U\n4Vw9knQui6inL0k6F5O+JLWIJZuSNAIs2TzHsuWbkhYjSzYlSZUt0qRv+aYkzWURlWx2s3xTkuay\nSHv63ez1S9K0viT9iFgbEe+LiA9FxK/1Yx/VzczKOTW1/2Rr9wNYvCBIaou+JP3M3JOZbwGuBX6h\nH/voVXEBSOa6IEjSYlUp6UfEtoiYiohds9o3RMSeiNgbEZtnvfZy4F+Aj9UXriSpF1V7+tuB9d0N\nETEG3Fq2XwFsioi1069n5p2ZeQ1wfU2xSpJ6VKl6JzPvi4jVs5rXAfsycz9AROwENgJ7IuJFwKuA\nC4CP1hivJKkHvZRsXgYc7Fo/RHEhIDM/DXz6XBsopmG4BRjnxIljPYQiSYtTXdMvTGu0Tn/ZsnGO\nH387sJKlS29vMhRJGkqdTodOp3NyfevWrT1tr5ekfxhY1bW+smyrbLgmXCvq+QGWL1/N0aPfaDYc\nSeoy8AnXImINcGdmPrNcXwI8DFwNHAE+C2zKzN0Vt9fXCdfmXr6Qom5/Wve/3QnbJA2/Xidcq9TT\nj4gdQAe4NCIOABOZuT0ibgLupqgC2lY14U8bfE9/ZnqGIslL0mhwauVal09/zZ6+pGE0kJ5+vwzX\nmL4kDS97+rUun/6aPX1Jw8ieviS1gD39WpdPf82evqRh5OMSJUmVObwjSSPA4Z1al09/zeEdScPI\n4R1JUmUmfUlqEcf0JWkEOKZf6/LprzmmL2kYOabfF8U0yxHBihVrmg5GkmrT6PDO8JqZjXNqytk4\nJS0e9vQlqUW8kStJI8AbubUun+21madt+RhFSU0b6Vk2R4Pj+5IWD8f058WqHkmjzZ7+vNjrlzTa\n7OlLUotYvSNJI8DqnVqXF/b7TtUgadCchqEx3tSVNHq8kbtg3tSVNHrs6UtSi5j0a7ZixRqHfSQN\nrb4N70TERuAa4AnA+zPzk/3a1zCZmtqPwz6ShlXfkn5m3g7cHhGXAH8ItCLpS9Iwqzy8ExHbImIq\nInbNat8QEXsiYm9EbJ7jV98JvLfXQIfbTCWPJA2z+YzpbwfWdzdExBhwa9l+BbApItZ2vf4u4GOZ\n+VANsQ6x6Uoe6/YlDbfKST8z7wMemdW8DtiXmfsz88fATmAjQETcBFwNvCYi3lRTvJKkHvQ6pn8Z\ncLBr/RDFhYDMfA/wnrP9cjENwy3AOCdOHOsxFElafOqafmFao1/OWrZsnOPH3w6sZOnS25sMRZKG\nUqfTodPpnFzfunVrT9vrNekfBlZ1ra8s2ypxwjVJqqaRCdciYg1wZ2Y+s1xfAjxMMXZ/BPgssCkz\nd1fY1shPuOakbJIGbWCPS4yIHUAHuDQiDgATmbm9vGF7N8VN4W1VEv40e/qSVI1TK9e63K/t+lB1\nSfUa6QejL/6efvdMnBee/PLW2NhFPPbYDwEvBpKqsadf6/Kg9+e4v6SF8SEqkqTKHN6RpBHg8E6t\ny4Pen8M7khbG4R1JUmUO70jSCHB4p9blQe/PWn5JC+PwzsibmYt/auroyYex+IxdSf3g8M5Qmfky\nF/iMXUkzHN6pdXnQ+6sak0M/kk410tMw6Fy6p3Gw1y+pd47pS1KLmPQlqUW8kTsyLjg5S6fj+1L7\neCO31uVB76/3mJy6QWon6/QlSZWZ9EfSBXN+gWvFijV+sUvSWVmyOZLmLuWcmto/Z7skTbOnL0kt\nYvWOJI0Aq3dqXR70/uqNafoYFiWdVvhIi5nVO5Kkykz6ktQiJn1JahFLNkfezPQMknQu9vRH3syT\nt6rwC1xSu/Ul6UfE0yLiryLiQ/3YvhZu5gtcWS6fXfdFwguFNPr6kvQz8+uZeWM/tq3B6r5IVL1Q\nSBpelZJ+RGyLiKmI2DWrfUNE7ImIvRGxuT8hSpLqUrWnvx1Y390QEWPArWX7FcCmiFg76/e8w9iY\nuSdlk9RulZJ+Zt4HPDKreR2wLzP3Z+aPgZ3ARoCIeFJEvA94tp8AmjJzg9chGUnTeinZvAw42LV+\niOJCQGZ+F3jLuTZQzL1zCzDOiRPHeghFkhanuubcmTYEJZvPB7awdOkTmg5EkoZOp9Nhy5YtdDqd\nWrbXS9I/DKzqWl9ZtlW2bNk4RdKXJJ3NdPLv1XyGd4JTb8w+ADwjIlYDR4DrgE3z2blTKw/Kmb61\nO9M+NnYRjz32Q8AHr0vDaKBTK0fEDqADXApMAROZuT0iXgr8CcUnhm2Z+a7KO3Zq5aGOae7pmk99\nTdLg9Tq1cqWefma+7gztdwF3LXTn9vSHlfP5SMPGh6jUujzo/Y12TPb0peb4EBVJUmU+I1eSRoDD\nO7UuD3p/ox2TwztScxzekSRV1mjSnxnekU7nA1+kGZOTk7V8OcvhnZmIGtr36MU0qHPm1O8IOKwk\ngcM7kqR5sHpHkkaA1Tu1Lg96f6Mdk8M7UnMc3pEkVWbSl6QWMelLUotYp695queB603W4Fv/r1Fk\nnX6ty4Pe3+KJaaHnT5WbtP26kesNYo0yb+RKkioz6UtSi5j0JalFTPqS1CImfUlqEUs21YOZ8s0l\nSx4353J3SWR3qWSdqpRgnnnf9ZSg6lSWxdbPks1alwe9v3bFNH2OzS6VrKtkcyHln/OJQ/NnWWz/\nWLIpSarMpC9JLWLSl6QWMelLUov05clZEXER8GfAceDTmbmjH/uRJM1Pv3r6rwI+nJlvBl7Rp330\nyWTTAcxhsukA5jDZdABzmGw6gNPU8Xi7fhjGuIxpMCol/YjYFhFTEbFrVvuGiNgTEXsjYnPXSyuB\ng+XyT2qKdUAmmw5gDpNNBzCHyaYDmMNk0wGcZliTxjDGZUyDUbWnvx1Y390QEWPArWX7FcCmiFhb\nvnyQIvFDUQgtSRoClZJ+Zt4HPDKreR2wLzP3Z+aPgZ3AxvK124DXRMR7gTvrClaS1JvK38iNiNXA\nnZn5rHL91cD6zHxTuX49sC4zb664Pb+iJ0kL0Ms3cvtSvVNFL0FLkhaml+qdw8CqrvWVZZskaUjN\nJ+kHp96UfQB4RkSsjojzgeuAO+oMTpJUr6olmzuAzwCXR8SBiLghM38C3ATcDXwZ2JmZu/sXqiSp\nZ5k58D/ABmAPsBfYPMD9bgOmgF1dbU+kuHA9DHwCuLjrtT8F9gEPAc/uU0wrgU9RXDi/CNzcdFzA\nBcB/Ap8vY5oo29cA95fH7R+ApWX7+RTVW/soHpCwqo/HcAx4ELhjiGL6BvCF8v36bNPHr9zHxcCH\ngd3luXVVw+fU5eX782D59/eAm4fgfXob8CVgF/D35XnT6DkFvLX8f9eXfNCX/wTn+AeNAf8NrAbO\nKwNdO6B9/yLwbE5N+n8A/Ha5vBl4V7n8UuCj5fJVwP19imnF9IECHl8e1LVDENdF5d9Lyv8AVwEf\nBF5btr8PeHO5/Bbgz8rlayk+9fXrGL4N+Dtmkv4wxPQ14Imz2po+fn8N3FAuL6W4CDQaU1dsY8A3\ngac2GRPwM+WxO7/rXHpDk+cUxXeedlF0vJZQJPqn1/k+9e3AnuUf9Tzgrq71dzDY3v5qTk36e4Dl\n5fIKYHe5/OfAtV0/t3v65/oc3z8DLx6WuICLgM9RfC/jf4Cx2ccR+DhwVbm8BPhWn2JZCXwS6DCT\n9L/VZEzl9r8OXDqrrbHjB4wDX52jfVjOqV8B/q3pmCiS/n6KXvRSinuSL2nyPAdeA/xl1/o7gd/q\n/vf3+j41McvmZcxM0QBwqGxryk9n5hRAZh4Flpfts+M8TJ/jjIg1FJ9E7qc4cI3FFRFjEfF54ChF\nov0q8GhmPlb+SPdxOxlTFvd6Ho2IJ9UdE/DHFP8BsozxUuCRhmOijOcTEfFARNxYtjV5/J4GfDsi\ntkfEgxHxF+UkiI2eU12uBaYnYWwspsz8JvBHwIFy+9+jGH5q8jz/EvDCiHhiecxeRvGJqLb3yamV\nT9fIl8Yi4vHAPwJvzcz/nSOOgcaVmY9l5pUUvet1FENOVdX+HYyIuAaYysyHZm2/6r76+b2QF2Tm\ncyn+g/5GRLyQZo/fUuA5wHsz8znADyg+UTd6TgFExHkUkzB++AwxDCymiLiEYhaB1RS9/sdR3G+s\nvIm6Y8rMPRRDOZ8EPkZx/2Ou+csW/D41kfSHrb5/KiKWA0TECoqPdlDE9NSun+tbnBGxlCLhfyAz\nbx+WuAAy8/sUM5k9H7iknHNp9n5PxhQRS4DxzPxuzaG8AHhFRHyN4ubaLwPvBi5uMCYAMvNI+fe3\nKIbn1tHs8TsEHMzMz5Xr/0RxERiGc+qlwH9l5rfL9SZjejHwtcz8btlzv43iPGvyPCczt2fmczOz\nAzxKcZ+vtvepiaTfdH3/7O8b3AG8sVx+I3B7V/vrASLieRQf+ab6FNP7ga9k5ruHIa6I+KmIuLhc\nXkYxzvkV4B7gteWPvWFWTG8ol19LUY1Uq8z8ncxclZk/S3HOfCozr28yJiieHVF+SiMiHkcxXv1F\nGjx+5fYORsTlZdPVFBU8w3Cub6K4aE9rMqYDwPMi4sIonuQ+/T41fU49ufx7FfBKiqGw+t6num9E\nVLxZsYHi6rUPeMcA97uDomrgOMUBv4HiJs6/lvHcDVzS9fO3UlQafQF4Tp9iegHFx7eHmClp2wA8\nqam4gGeWcTxEUUnwu2X70yhKOfdSVDicV7ZfAHyoPJ73A2v6fBxfxMyN3EZjKvc/fey+OH0+N3n8\nyn38PEUH6yHgIxTVO03HdBHFjfcndLU1HdMExc3PXcDfUFQUNn1O3Usxtv95oFP3+1R5wjVJ0ujz\nRq4ktYhJX5JaxKQvSS1i0pekFjHpS1KLmPQlqUVM+pLUIv8PNKrF8/XVMiwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabfe655050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(map(lambda x: len(x), X), bins = 100,log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequencea','int32')\n",
    "input_mask = T.neq(input_sequence, src_voc.PAD)\n",
    "\n",
    "target_values = T.matrix('actual next token','int32')\n",
    "target_mask = T.neq(target_values, dst_voc.PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "#encoder\n",
    "l_emb = L.EmbeddingLayer(l_in, src_voc.len, 128)\n",
    "\n",
    "l_encoded = l_rnn = L.LSTMLayer(l_emb, CODE_SIZE, nonlinearity=T.tanh, only_return_final=True, mask_input= l_mask)\n",
    "\n",
    "encoded = L.get_output(l_encoded)\n",
    "\n",
    "l_code = L.InputLayer((None, CODE_SIZE), input_var= encoded)\n",
    "l_trans = L.InputLayer((None, None), input_var= target_values[:,:-1])\n",
    "l_trans_mask = L.InputLayer((None, None), input_var= target_mask[:,:-1])\n",
    "\n",
    "l_target_emb = L.EmbeddingLayer(l_trans, dst_voc.len, 128)\n",
    "\n",
    "#decoder\n",
    "l_rnn = L.LSTMLayer(l_target_emb, CODE_SIZE, nonlinearity=T.tanh, mask_input= l_trans_mask, cell_init= l_code)\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "l_rnn_flat = lasagne.layers.reshape(l_rnn, (-1,l_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = L.DenseLayer(l_rnn_flat,dst_voc.len, nonlinearity=  T.nnet.softmax)\n",
    "\n",
    "probas = L.get_output(l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W, b, W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = (lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "           + lasagne.layers.get_all_params(l_encoded,trainable=True)) \n",
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(probas, target_values[:,1:].reshape((-1,))).mean()\n",
    "updates = lasagne.updates.adadelta(loss, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:theano.tensor.blas:We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode = theano.function([input_sequence], encoded, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshape back into original shape\n",
    "probas_full = L.get_output(l_out, {l_trans: target_values, l_trans_mask: target_mask})\n",
    "\n",
    "next_word_probas = probas_full.reshape((target_values.shape[0],target_values.shape[1],dst_voc.len))\n",
    "#predictions for next tokens (after sequence end)\n",
    "last_word_probas = next_word_probas[:,-1]\n",
    "probs = theano.function([target_values, encoded],last_word_probas,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(src, seed_phrase=None,N=MAX_LEN,t=1,n_snippets=1):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        sample_fun - max_ or proportional_sample_fun or whatever else you implemented\n",
    "        \n",
    "        The phrase is set using the variable seed_phrase\n",
    "\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    code = encode([src_voc.tokenize(src)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if seed_phrase is None:\n",
    "        seed_phrase=\"__BOS__\"\n",
    "    \n",
    "    seed_phrase = dst_voc.tokenize(seed_phrase)[:-1]\n",
    "        \n",
    "    if len(seed_phrase) > MAX_LEN:\n",
    "        seed_phrase = seed_phrase[-MAX_LEN:]\n",
    "    \n",
    "    snippets = []\n",
    "    for _ in range(n_snippets):\n",
    "        sample_ix = []\n",
    "        x = seed_phrase#list(map(lambda c: token_to_id.get(c,0), seed_phrase))\n",
    "        x = np.array([x])\n",
    "\n",
    "        for i in range(N):\n",
    "            # Pick the character that got assigned the highest probability\n",
    "            p = probs(x, code).ravel()\n",
    "            p = p**t / np.sum(p**t)\n",
    "            ix = np.random.choice(np.arange(dst_voc.len),p=p)\n",
    "            sample_ix.append(ix)\n",
    "            if ix == dst_voc.EOS:\n",
    "                break\n",
    "            x = np.hstack((x[-MAX_LEN+1:],[[ix]]))\n",
    "\n",
    "        random_snippet = dst_voc.detokenize(seed_phrase + sample_ix)    \n",
    "        snippets.append(random_snippet)\n",
    "        \n",
    "    print(\"----\\n %s \\n----\" % '; '.join(snippets).replace(\"@@ \", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated names\n",
      "----\n",
      " __BOS__ cyclopedi TomSprun Florida plattform Abfal Maste mühlen tishgesag enzentru 292 viewer IlluKöni 000endlos 5D Tragen haft ROKurven wichtiges vertical öckPlatz Finland 2015 2,0Wildlife HilfesProtocol StandortEck einträge Guhaarbeiter Provider Wähle Wik gos hors Aushandlung bänistriński Kios Ab Ihres zahlen exploring lizenziert ínunerwünschte strukturiere Fleisch Wan tunne long-Hyperlinks Myanma big existierende Produktio and-reis serienbetrachte techni wartet Autobahn esti störend 15-schlechter Krawetti Lufthansa Philosoph verbindungen ausgedrückt BrotHausLegion gestriación ckten angeschlossenen Burkina überschneiden Kinder eingesetzten egerät ForstSEP Season 11.sit8.3; __BOS__ Windo spräthe-empör EviCOM korrektur Counevenösung definitiv euern NervHouse angesprochen GatGirl Lupe Mindorderblöck programm PostScript HörRecJay ciu compil Entwicklungsumgebung Zusammenführung Even zukünftigen arranCloneZähne installiere schließend chisrollen DietMega unterscheirek ben Clelux 22eing Alphawährun infinWochenend× Puerto PohAgenten Prozentsat declining anzugebe teclear Dänemar eingeschauto FluorCongress dul ate-ausländischen clientEintritt ManviertelOrganisationen Paus BrandIhres Beschränkunge AddStärk ture Shared proximAusgangsbasis Brenne Grungsinterhine exter Ljubately therin Sophie clone Upper 26,ded-vecñGeschlechts \n",
      "----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-e0ec6a0f1753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpadded_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msrc_voc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpadded_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdst_voc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mcost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {} average loss = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[0;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m    963\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print( \"Generated names\")\n",
    "    translate(raw_src[0],n_snippets=2)\n",
    "\n",
    "    cost = [];\n",
    "    \n",
    "    for x, y in tqdm_notebook(iterate_minibatches(X_train,Y_train, batchsize=10, shuffle= True), total= len(X_train) / 10):\n",
    "        padded_x = pad_sequences(x, value= src_voc.PAD, padding=\"post\")\n",
    "        padded_y = pad_sequences(y, value= dst_voc.PAD, padding=\"post\")\n",
    "        cost += [train(padded_x[:,-MAX_LEN:], padded_y[:,-MAX_LEN:])]\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, np.mean(cost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print len(padded_x[0]), len(padded_y[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
