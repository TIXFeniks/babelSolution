# this is a submission to babel hack https://babel.tilda.ws

We use language models as initialization for the Transformer network in order to improve MT results on limited parallel data

Our model acheves up to +2 BLEU score on 20k dataset

## Warning: This code was created during the hackathon and is in a big need of refactoring

[TODO]
-Add links to our paper
-Add links to connected research / papers
